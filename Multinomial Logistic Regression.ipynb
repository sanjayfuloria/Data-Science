{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Multinomial Logistic regression\n",
    "Multinomial logistic regression is the generalization of logistic regression algorithm. If the logistic regression algorithm used for the multi-classification task, then the same logistic regression algorithm called as the multinomial logistic regression.\n",
    "\n",
    "The difference in the normal logistic regression algorithm and the multinomial logistic regression in not only about using for different tasks like binary classification or multi-classification task. In much deeper It’s all about using the different functions.\n",
    "\n",
    "In the logistic regression, the black function which takes the input features and calculates the probabilities of the possible two outcomes is the Sigmoid Function. Later the high probabilities target class is the final predicted class from the logistic regression classifier.\n",
    "\n",
    "When it comes to the multinomial logistic regression the function is the Softmax Function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sanjayfuloria'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/sanjayfuloria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Python Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    " \n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "py.sign_in('sanjayfuloria', 'E46d36hAM3ufMHmwjpLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='sanjayfuloria', api_key='E46d36hAM3ufMHmwjpLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glass_data=pd.read_csv(\"glass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Glass dataset headers\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    # Loading the Glass dataset in to Pandas dataframe \n",
    "    glass_data = pd.read_csv(\"glass.csv\", names=glass_data_headers)\n",
    " \n",
    "    print (\"Number of observations :: \", len(glass_data.index))\n",
    "    print (\"Number of columns :: \", len(glass_data.columns))\n",
    "    print (\"Headers :: \", glass_data.columns.values)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded dataset is not having the header, So we created the glass_data_headres.\n",
    "We are loading the dataset into pandas dataframe by passing the dataset location and the headers.\n",
    "Next printing the loaded dataframe observations, columns and the headers name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations ::  214\n",
      "Number of columns ::  11\n",
      "Headers ::  ['Id' 'RI' 'Na' 'Mg' 'Al' 'Si' 'K' 'Ca' 'Ba' 'Fe' 'glass-type']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_with_color_dimension_graph(feature, target, layout_labels):\n",
    "    \"\"\"\n",
    "    Scatter with color dimension graph to visualize the density of the\n",
    "    Given feature with target\n",
    "    :param feature:\n",
    "    :param target:\n",
    "    :param layout_labels:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    trace1 = go.Scatter(\n",
    "        y=feature,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size='16',\n",
    "            color=target,\n",
    "            colorscale='Viridis',\n",
    "            showscale=True\n",
    "        )\n",
    "    )\n",
    "    layout = go.Layout(\n",
    "        title=layout_labels[2],\n",
    "        xaxis=dict(title=layout_labels[0]), yaxis=dict(title=layout_labels[1]))\n",
    "    data = [trace1]\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    # plot_url = py.plot(fig)\n",
    "    py.image.save_as(fig, filename=layout_labels[1] + '_Density.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    glass_data = pd.read_csv(\"data.csv\", names=glass_data_headers)\n",
    "    print (\"glass_data_RI :: \", list(glass_data[\"RI\"][:10]))\n",
    "    print (\"glass_data_target :: \", np.array([1, 1, 1, 2, 2, 3, 4, 5, 6, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass_data_RI ::  [0.0027000000000000001, 0.0083999999999999995, 0.023199999999999998, 0.0121, 0.0030999999999999999, 0.0044999999999999997, 0.0201, 0.0080999999999999996, 0.014500000000000001, 0.0089999999999999993]\n",
      "glass_data_target ::  [1 1 1 2 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are the dummy feature and the target.\n",
    "\n",
    "glass_data_RI: Is the feature and the values of this feature are the refractive index. These are the first 10 values from the glass identification dataset.\n",
    "glass_data_target: Is the target and the values are the different glass types. In fact, I covered all the glass types (7 types.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use the above dummy data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    \n",
    "    glass_data = pd.read_csv(\"glass.csv\", names=glass_data_headers)\n",
    " \n",
    "    print (\"glass_data_RI :: \", list(glass_data[\"RI\"][:10]))\n",
    "    print (\"glass_data_target :: \", np.array([1, 1, 1, 2, 2, 3, 4, 5, 6, 7]))\n",
    "    # Graph Labels\n",
    "    graph_labels = [\"Number of Observations\", \"RI & Glass Type\", \"Sample RI - Glass Type Density Graph\"]\n",
    " \n",
    "    scatter_with_color_dimension_graph(list(glass_data[\"RI\"][:10]),np.array([1, 1, 1, 2, 2, 3, 4, 5, 6, 7]), graph_labels)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glass_data_RI ::  [1.52101, 1.5176100000000001, 1.5161799999999999, 1.51766, 1.51742, 1.51596, 1.5174299999999998, 1.51756, 1.51918, 1.51755]\n",
      "glass_data_target ::  [1 1 1 2 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The above graph helps to visualize the relationship between the feature and the target (7 glass types)\n",
    "The Yellow circle is for glass type 7.\n",
    "The right sidebar will help to know the circle type (target glass type) by its color and the left side values are the corresponding feature values.\n",
    "If we plot more number of observations we can visualize for what values of the features the target will be the glass type 7, likewise for all another target(glass type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create a function which creates the density graph and the saves the above kind of graphs for all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_density_graph(dataset, features_header, target_header):\n",
    "    \"\"\"\n",
    "    Create density graph for each feature with target\n",
    "    :param dataset:\n",
    "    :param features_header:\n",
    "    :param target_header:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for feature_header in features_header:\n",
    "        print (\"Creating density graph for feature:: {} \".format(feature_header))\n",
    "        layout_headers = [\"Number of Observation\", feature_header + \" & \" + target_header,\n",
    "                          feature_header + \" & \" + target_header + \" Density Graph\"]\n",
    "        scatter_with_color_dimension_graph(dataset[feature_header], dataset[target_header], layout_headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function create_density_graph takes the dataset, features_header and target_headers as input parameters.\n",
    "Inside the function, we are considering each feature_header in the features_header and calling the function scatter_with_clolor_dimenstion_graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s call the above function inside the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    glass_data = pd.read_csv(\"glass.csv\", names=glass_data_headers)\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    create_density_graph(glass_data, glass_data_headers[1:-1], glass_data_headers[-1])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating density graph for feature:: RI \n",
      "Creating density graph for feature:: Na \n",
      "Creating density graph for feature:: Mg \n",
      "Creating density graph for feature:: Al \n",
      "Creating density graph for feature:: Si \n",
      "Creating density graph for feature:: K \n",
      "Creating density graph for feature:: Ca \n",
      "Creating density graph for feature:: Ba \n",
      "Creating density graph for feature:: Fe \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code saves the below graphs, Each graph gives the relationship between the feature and the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please spend some time on understanding each graph to know which features and the target having the good relationship. So we can use those features to build the multinomial logistic regression model.\n",
    "\n",
    "To build the multinomial logistic regression I am using all the features in the Glass identification dataset. You use the most suitable features you think from the above graphs and use only those features to model the multinomial logistic regression.\n",
    "\n",
    "Training the multinomial logistic regression model requires the features and the corresponding targets. For this, we are going to split the dataset into four datasets. Which are\n",
    "\n",
    "train_x\n",
    "test_x\n",
    "train_y\n",
    "test_y\n",
    "We are going to use the train_x and train_y for modeling the multinomial logistic regression model and use the test_x and test_y for calculating the accuracy of our trained multinomial logistic regression model.\n",
    "\n",
    "Now let’s split the loaded glass dataset into four different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    glass_data = pd.read_csv(\"glass.csv\", names=glass_data_headers)\n",
    " \n",
    "    train_x, test_x, train_y, test_y = train_test_split(glass_data[glass_data_headers[:-1]],\n",
    "    glass_data[glass_data_headers[-1]], train_size=0.7)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the scikit-learn train_test_split method to split the glass dataset.\n",
    "As we are passing 0.7 as the train_size value, The train_test_split method will split the glass dataset randomly 70% for training and remaining 30% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the logistic regression for multi-classification\n",
    "In the first approach, we are going use the scikit learn logistic regression classifier to build the multi-classification classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    glass_data = pd.read_csv(\"glass.csv\", names=glass_data_headers)\n",
    " \n",
    "    train_x, test_x, train_y, test_y = train_test_split(glass_data[glass_data_headers[:-1]],\n",
    "    glass_data[glass_data_headers[-1]], train_size=0.7)\n",
    "    # Train multi-class logistic regression model\n",
    "    lr = linear_model.LogisticRegression()\n",
    "    lr.fit(train_x, train_y)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function LogisticRegression in scikit learn linear_model method to create the logistic regression model instance.\n",
    "Next using the fit method with the train_x and train_y to fit the logistic regression model for the glass identification training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the multinomial logistic regression\n",
    "In the second approach, we are going pass the multinomial parameter before we fit the model with train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    glass_data = pd.read_csv(\"glass.csv\", names=glass_data_headers)\n",
    " \n",
    "    train_x, test_x, train_y, test_y = train_test_split(glass_data[glass_data_headers[:-1]],\n",
    "    glass_data[glass_data_headers[-1]], train_size=0.7)\n",
    " \n",
    "    # Train multinomial logistic regression\n",
    "    mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(train_x, train_y)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the accuracies\n",
    "Now compare the train and test accuracies of both the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    glass_data_headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"glass-type\"]\n",
    "    glass_data = pd.read_csv(\"glass.csv\", names=glass_data_headers)\n",
    " \n",
    "    train_x, test_x, train_y, test_y = train_test_split(glass_data[glass_data_headers[:-1]],\n",
    "    glass_data[glass_data_headers[-1]], train_size=0.7)\n",
    " \n",
    "    # Train multi-classification model with logistic regression\n",
    "    lr = linear_model.LogisticRegression()\n",
    "    lr.fit(train_x, train_y)\n",
    "    \n",
    "    #Test the model on new data which is entered manually\n",
    "    newdata=np.array([215,1.5232,13.14,2.84,1.28,72.85,0.55,9.07,0,0])\n",
    "    newdata=newdata.reshape(1,-1)\n",
    "    lr = linear_model.LogisticRegression()\n",
    "    lr.fit(train_x, train_y)\n",
    "    yhat=lr.predict(newdata)\n",
    "    print(\"The predicted value for new data is ::\", yhat)\n",
    "    \n",
    " \n",
    "    # Train multinomial logistic regression model\n",
    "    mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(train_x, train_y)\n",
    "    \n",
    "    print (\"Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_y, lr.predict(train_x)))\n",
    "    print (\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, lr.predict(test_x)))\n",
    "    \n",
    "    print (\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_y, mul_lr.predict(train_x)))\n",
    "    print (\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, mul_lr.predict(test_x)))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the accuracy of the trained multinomial logistic regression models we are using the scikit learn metrics method.\n",
    "We are calling the metrics method accuracy_score function with actual targets and the predicted targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted value for new data is :: [7]\n",
      "Logistic regression Train Accuracy ::  0.892617449664\n",
      "Logistic regression Test Accuracy ::  0.876923076923\n",
      "Multinomial Logistic regression Train Accuracy ::  1.0\n",
      "Multinomial Logistic regression Test Accuracy ::  1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial logistic regression model Accuracy\n",
    "From the result, we can say that using the direct scikit-learn logistic regression is getting less accuracy than the multinomial logistic regression model. Now you use the code and play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-fcd341791873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnewdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m215\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.5232\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13.14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m72.85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9.07\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnewdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "newdata=np.array([215,1.5232,13.14,2.84,1.28,72.85,0.55,9.07,0,0,1])\n",
    "newdata=newdata.shape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-33c8cff00d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "yhat=lr.predict(newdata)\n",
    "print(\"The predicted value for new data is ::\", yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
